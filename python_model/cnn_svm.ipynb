{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "from scipy.stats import itemfreq\n",
    "import random\n",
    "import os.path\n",
    "\n",
    "import theano\n",
    "import lasagne\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from nolearn.lasagne import visualize\n",
    "\n",
    "# import user defined load_data to build input data\n",
    "from load_data import Data\n",
    "from utils import save_network\n",
    "from model_predictions import build_cnn\n",
    "from model_predictions import generate_features\n",
    "from model_predictions import extract_features\n",
    "\n",
    "# Enter your own file path here, in the path it should contain three\n",
    "# directories, model, data, word2vec\n",
    "FILE_PATH = '../files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Sports data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading csv: \n",
      "  tennis\n",
      "  basketball\n",
      "  baseball\n",
      "  hockey\n",
      "  volleyball\n",
      "Note: pre-process changes the dataframe inplace.\n",
      "Removing  ['#tennis', '#basketball', '#baseball', '#hockey', '#volleyball']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sweatbandactive win head pro racket worth f te...</td>\n",
       "      <td>4</td>\n",
       "      <td>[sweatbandactive, win, head, pro, racket, wort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cmail sport us davis cup captain jim courier t...</td>\n",
       "      <td>4</td>\n",
       "      <td>[cmail, sport, us, davis, cup, captain, jim, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>learn roger federer recent winning streak</td>\n",
       "      <td>4</td>\n",
       "      <td>[learn, roger, federer, recent, winning, streak]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paddyspower best odds uk football golf premier...</td>\n",
       "      <td>4</td>\n",
       "      <td>[paddyspower, best, odds, uk, football, golf, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tennisexpress want express gift card silly que...</td>\n",
       "      <td>4</td>\n",
       "      <td>[tennisexpress, want, express, gift, card, sil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class  \\\n",
       "0  sweatbandactive win head pro racket worth f te...      4   \n",
       "1  cmail sport us davis cup captain jim courier t...      4   \n",
       "2          learn roger federer recent winning streak      4   \n",
       "3  paddyspower best odds uk football golf premier...      4   \n",
       "4  tennisexpress want express gift card silly que...      4   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [sweatbandactive, win, head, pro, racket, wort...  \n",
       "1  [cmail, sport, us, davis, cup, captain, jim, c...  \n",
       "2   [learn, roger, federer, recent, winning, streak]  \n",
       "3  [paddyspower, best, odds, uk, football, golf, ...  \n",
       "4  [tennisexpress, want, express, gift, card, sil...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports_dic = {'basketball':1, 'hockey':2, 'baseball':3, 'tennis':4, 'volleyball':5}\n",
    "sp_data = Data(sports_dic, FILE_PATH)\n",
    "sp_df = sp_data.csv_df(['text']) # load data\n",
    "rm_hashtags = ['#'+s for s in sports_dic.keys()]\n",
    "sp_data.pre_process(sp_df, rm_list=rm_hashtags) # pre-process data\n",
    "# save this to csv \n",
    "sp_df.to_csv(FILE_PATH+'data/all_sports.csv', index=False)\n",
    "sp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if you want to save the processed file to csv\n",
    "sp_df.to_csv('../files/data/all_sports_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    10000\n",
       "3    10000\n",
       "2    10000\n",
       "1    10000\n",
       "5     4755\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets take a look of the \n",
    "sp_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# comment out if do not want class balance\n",
    "\n",
    "# airline_df = airline_data.balance_class(airline_df)\n",
    "# # and check again\n",
    "# airline_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model tweets600.model.bin ...\n",
      "Done building.\n"
     ]
    }
   ],
   "source": [
    "# train or load the model\n",
    "model = sp_data.build_wordvec(size=600, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length is:  23\n",
      "npy already exists, loading ...\n",
      "Done loading npy file.\n",
      "npy already exists.\n"
     ]
    }
   ],
   "source": [
    "# max_len is the max length of a sentence in our data, this decides the padding\n",
    "max_len = sp_data.max_len(sp_df)\n",
    "# convert our aline data to vector\n",
    "data = sp_data.convert2vec(sp_df, max_len, model, name='sports-600')\n",
    "#data = airline_data.standarize(data)\n",
    "sp_data.save_vec(data, name='sports-600')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can uncomment this to check if the wordvec makes sense\n",
    "# model.wv.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create data that gets fed into classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N, M, D: 44755 23 600\n",
      "(44755, 1, 23, 600)\n",
      "(44755,)\n",
      "label saved as ../files/data/labels\n"
     ]
    }
   ],
   "source": [
    "N, M, D = data.shape\n",
    "print \"N, M, D:\", N, M, D\n",
    "data = data.reshape(-1, 1, M, D).astype(theano.config.floatX) # theano needs this way\n",
    "label = sp_df['class']\n",
    "# label = np.int8(label) - 1# seems like theano also needs this\n",
    "print data.shape\n",
    "print label.shape\n",
    "\n",
    "# one-hot encode label\n",
    "n_classes = 5\n",
    "label = np.eye(n_classes, dtype=int)[label.values-1]\n",
    "# save the one-hot-enconded labels\n",
    "# i.e. classes, 1-5\n",
    "#1 = [1, 0, 0, 0, 0]\n",
    "#2 = [0, 1, 0, 0, 0]\n",
    "\n",
    "file_name = FILE_PATH+'data/labels'\n",
    "np.save(file_name, label)\n",
    "print \"label saved as {}\".format(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # train our model or load model if it exists\n",
    "# def train_cnn(net, X_train, y_train, model_name='nn_cnn001'):\n",
    "#     model_file = FILE_PATH+'model/' + model_name\n",
    "#     if os.path.isfile(model_file):\n",
    "#         print (\"Loading existing model ...\")\n",
    "#         net.load_params_from(model_file)\n",
    "#     else:\n",
    "#         # Train the network\n",
    "#         net.fit(X_train, y_train)\n",
    "#         net.save_params_to(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # initialize\n",
    "# cnn= build_cnn(M, D)\n",
    "# # train\n",
    "# train_cnn(cnn, data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize.plot_conv_weights(cnn.layers_['conv2d1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # now transfer to svm\n",
    "# # stratified cross-validation\n",
    "# sss = StratifiedShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "# n_cv = 1\n",
    "# for train_index, val_index in sss.split(data, label):\n",
    "#     t1 = time.time()\n",
    "#     data_train, data_val = data[train_index], data[val_index]\n",
    "#     label_train, label_val = label[train_index], label[val_index]\n",
    "    \n",
    "#     freq_train = itemfreq(label_train)\n",
    "#     print \"train freq\", freq_train[:,1]\n",
    "#     freq_val = itemfreq(label_val)\n",
    "#     print \"val freq\", freq_val[:,1]\n",
    "\n",
    "#     # pass through cnn\n",
    "#     extract_train = extract_features(cnn, data_train)\n",
    "#     extract_val = extract_features(cnn, data_val)\n",
    "#     clf = SVC(verbose=True, random_state=None)\n",
    "#     print \"Training cv {} ...\".format(n_cv)\n",
    "#     clf.fit(extract_train, label_train)\n",
    "#     acc = clf.score(extract_val, label_val)\n",
    "#     t2 = time.time()\n",
    "    \n",
    "#     print acc\n",
    "#     print \"\\n\"\n",
    "#     print \"Time took: {0:.2f} min\".format((t2-t1)/60)\n",
    "#     n_cv += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "# joblib.dump(clf, FILE_PATH+'svm-final.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
