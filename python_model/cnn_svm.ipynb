{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "from scipy.stats import itemfreq\n",
    "import random\n",
    "import os.path\n",
    "\n",
    "import theano\n",
    "import lasagne\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from nolearn.lasagne import visualize\n",
    "\n",
    "# import user defined load_data to build input data\n",
    "from load_data import Data\n",
    "from utils import save_network\n",
    "from model_predictions import build_cnn\n",
    "from model_predictions import generate_features\n",
    "from model_predictions import extract_features\n",
    "\n",
    "# Enter your own file path here, in the path it should contain two \n",
    "# directories, data and word2vec\n",
    "FILE_PATH = '/home/sam/Hhd/twitter_sentiment/'\n",
    "# FILE_PATH = '/home/sam/Data/twitter_sentiment/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Airline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading csv: Airline-Sentiment-2-w-AA.csv ...\n",
      "Note: pre-process changes the dataframe inplace.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>What  said</td>\n",
       "      <td>[said]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>plus youve added commercials to the experienc...</td>\n",
       "      <td>[plus, youve, added, commercials, experience, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I didnt today Must mean I need to take anothe...</td>\n",
       "      <td>[didnt, today, must, mean, need, take, another...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>its really aggressive to blast obnoxious ente...</td>\n",
       "      <td>[really, aggressive, blast, obnoxious, enterta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>and its a really big bad thing about it</td>\n",
       "      <td>[really, big, bad, thing]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0           neutral                                         What  said   \n",
       "1          positive   plus youve added commercials to the experienc...   \n",
       "2           neutral   I didnt today Must mean I need to take anothe...   \n",
       "3          negative   its really aggressive to blast obnoxious ente...   \n",
       "4          negative            and its a really big bad thing about it   \n",
       "\n",
       "                                           tokenized  \n",
       "0                                             [said]  \n",
       "1  [plus, youve, added, commercials, experience, ...  \n",
       "2  [didnt, today, must, mean, need, take, another...  \n",
       "3  [really, aggressive, blast, obnoxious, enterta...  \n",
       "4                          [really, big, bad, thing]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_data = Data('Airline-Sentiment-2-w-AA.csv', FILE_PATH)\n",
    "airline_df = airline_data.csv_df(['airline_sentiment', 'text']) # load data\n",
    "airline_data.pre_process(airline_df) # pre-process data\n",
    "# drop neutral\n",
    "# airline_df = airline_data.drop_value(airline_df, 'airline_sentiment', 'neutral')\n",
    "airline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "Done converting categorical to numeric, this changes df.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What  said</td>\n",
       "      <td>[said]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus youve added commercials to the experienc...</td>\n",
       "      <td>[plus, youve, added, commercials, experience, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I didnt today Must mean I need to take anothe...</td>\n",
       "      <td>[didnt, today, must, mean, need, take, another...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>its really aggressive to blast obnoxious ente...</td>\n",
       "      <td>[really, aggressive, blast, obnoxious, enterta...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and its a really big bad thing about it</td>\n",
       "      <td>[really, big, bad, thing]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                                         What  said   \n",
       "1   plus youve added commercials to the experienc...   \n",
       "2   I didnt today Must mean I need to take anothe...   \n",
       "3   its really aggressive to blast obnoxious ente...   \n",
       "4            and its a really big bad thing about it   \n",
       "\n",
       "                                           tokenized  class  \n",
       "0                                             [said]      2  \n",
       "1  [plus, youve, added, commercials, experience, ...      1  \n",
       "2  [didnt, today, must, mean, need, take, another...      2  \n",
       "3  [really, aggressive, blast, obnoxious, enterta...      3  \n",
       "4                          [really, big, bad, thing]      3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert categorical value to int class\n",
    "# class_label = {'positive': 1, 'negative': 2}\n",
    "class_label = {'positive': 1, 'neutral': 2, 'negative': 3}\n",
    "\n",
    "airline_df = airline_data.cat2num(airline_df, 'airline_sentiment', class_label, 'class')\n",
    "airline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    9178\n",
       "2    3099\n",
       "1    2363\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets take a look of the \n",
    "airline_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    3099\n",
       "2    3099\n",
       "1    2363\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comment out if do not want class balance\n",
    "airline_df = airline_data.balance_class(airline_df)\n",
    "# and check again\n",
    "airline_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What  said</td>\n",
       "      <td>[said]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus youve added commercials to the experienc...</td>\n",
       "      <td>[plus, youve, added, commercials, experience, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I didnt today Must mean I need to take anothe...</td>\n",
       "      <td>[didnt, today, must, mean, need, take, another...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seriously would pay  a flight for seats that ...</td>\n",
       "      <td>[seriously, would, pay, flight, seats, didnt, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes nearly every time I fly VX this ear worm ...</td>\n",
       "      <td>[yes, nearly, every, time, fly, vx, ear, worm,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                                         What  said   \n",
       "1   plus youve added commercials to the experienc...   \n",
       "2   I didnt today Must mean I need to take anothe...   \n",
       "3   seriously would pay  a flight for seats that ...   \n",
       "4   yes nearly every time I fly VX this ear worm ...   \n",
       "\n",
       "                                           tokenized  class  \n",
       "0                                             [said]      2  \n",
       "1  [plus, youve, added, commercials, experience, ...      1  \n",
       "2  [didnt, today, must, mean, need, take, another...      2  \n",
       "3  [seriously, would, pay, flight, seats, didnt, ...      3  \n",
       "4  [yes, nearly, every, time, fly, vx, ear, worm,...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model tweets600.model.bin ...\n",
      "Done building.\n"
     ]
    }
   ],
   "source": [
    "# train or load the model\n",
    "model = airline_data.build_wordvec(size=600, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length is:  19\n",
      "npy already exists, loading ...\n",
      "Done loading npy file.\n",
      "npy already exists.\n"
     ]
    }
   ],
   "source": [
    "# max_len is the max length of a sentence in our data, this decides the padding\n",
    "max_len = airline_data.max_len(airline_df)\n",
    "# convert our aline data to vector\n",
    "data = airline_data.convert2vec(airline_df, max_len, model, name='airline-3class-600')\n",
    "#data = airline_data.standarize(data)\n",
    "airline_data.save_vec(data, name='airline-3class-600')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can uncomment this to check if the wordvec makes sense\n",
    "# model.wv.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create data that gets fed into classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N, M, D: 8561 19 600\n",
      "(8561, 1, 19, 600)\n",
      "(8561,)\n"
     ]
    }
   ],
   "source": [
    "N, M, D = data.shape\n",
    "print \"N, M, D:\", N, M, D\n",
    "data = data.reshape(-1, 1, M, D).astype(theano.config.floatX) # theano needs this way\n",
    "label = airline_df['class']\n",
    "label = np.int8(label) - 1# seems like theano also needs this\n",
    "print data.shape\n",
    "print label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train our model or load model if it exists\n",
    "def train_cnn(net, X_train, y_train, model_name='nn_cnn'):\n",
    "    model_file = FILE_PATH+'nn_cnn'\n",
    "    if os.path.isfile(model_file):\n",
    "        print (\"Loading existing model ...\")\n",
    "        net.load_params_from(model_file)\n",
    "    else:\n",
    "        # Train the network\n",
    "        net.fit(X_train, y_train)\n",
    "        net.save_params_to(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model ...\n",
      "Loaded parameters to layer 'conv2d1' (shape 50x1x3x3).\n",
      "Loaded parameters to layer 'conv2d1' (shape 50x19x600).\n",
      "Loaded parameters to layer 'conv2d2' (shape 50x50x3x3).\n",
      "Loaded parameters to layer 'conv2d2' (shape 50x9x300).\n",
      "Loaded parameters to layer 'dense' (shape 30000x5000).\n",
      "Loaded parameters to layer 'dense' (shape 5000).\n",
      "Loaded parameters to layer 'output' (shape 5000x3).\n",
      "Loaded parameters to layer 'output' (shape 3).\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "cnn= build_cnn(M, D)\n",
    "# train\n",
    "train_cnn(cnn, data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/usr/lib/python2.7/dist-packages/matplotlib/pyplot.pyc'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAHlCAYAAADLMORiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxP8HbV3Ptypp0KUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f74e7854910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize.plot_conv_weights(cnn.layers_['conv2d1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train freq [1890 2479 2479]\n",
      "val freq [473 620 620]\n",
      "Extracting ... \n",
      "Extracting ... \n",
      "Training cv 1 ...\n",
      "[LibSVM]0.725627553999\n",
      "\n",
      "\n",
      "train freq [1890 2479 2479]\n",
      "val freq [473 620 620]\n",
      "Extracting ... \n",
      "Extracting ... \n",
      "Training cv 2 ...\n",
      "[LibSVM]0.72270869819\n",
      "\n",
      "\n",
      "train freq [1890 2479 2479]\n",
      "val freq [473 620 620]\n",
      "Extracting ... \n",
      "Extracting ... \n",
      "Training cv 3 ...\n",
      "[LibSVM]0.72270869819\n",
      "\n",
      "\n",
      "train freq [1890 2479 2479]\n",
      "val freq [473 620 620]\n",
      "Extracting ... \n",
      "Extracting ... \n",
      "Training cv 4 ...\n",
      "[LibSVM]0.712784588441\n",
      "\n",
      "\n",
      "train freq [1890 2479 2479]\n",
      "val freq [473 620 620]\n",
      "Extracting ... \n",
      "Extracting ... \n",
      "Training cv 5 ...\n",
      "[LibSVM]0.737886748395\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now transfer to svm\n",
    "# stratified cross-validation\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "n_cv = 1\n",
    "for train_index, val_index in sss.split(data, label):\n",
    "\n",
    "    data_train, data_val = data[train_index], data[val_index]\n",
    "    label_train, label_val = label[train_index], label[val_index]\n",
    "    \n",
    "    freq_train = itemfreq(label_train)\n",
    "    print \"train freq\", freq_train[:,1]\n",
    "    freq_val = itemfreq(label_val)\n",
    "    print \"val freq\", freq_val[:,1]\n",
    "\n",
    "    # pass through cnn\n",
    "    extract_train = extract_features(cnn, data_train)\n",
    "    extract_val = extract_features(cnn, data_val)\n",
    "    clf = SVC(verbose=True, random_state=None)\n",
    "    print \"Training cv {} ...\".format(n_cv)\n",
    "    clf.fit(extract_train, label_train)\n",
    "    acc = clf.score(extract_val, label_val)\n",
    "    print acc\n",
    "    print \"\\n\"\n",
    "    n_cv += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/sam/Hhd/twitter_sentiment/svm-final.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "joblib.dump(clf, FILE_PATH+'svm-final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
