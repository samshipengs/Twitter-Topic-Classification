{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "from scipy.stats import itemfreq\n",
    "import random\n",
    "import os.path\n",
    "\n",
    "import theano\n",
    "import lasagne\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from nolearn.lasagne import visualize\n",
    "\n",
    "# import user defined load_data to build input data\n",
    "from load_data import Data\n",
    "from utils import save_network\n",
    "from model_predictions import build_cnn\n",
    "from model_predictions import generate_features\n",
    "from model_predictions import extract_features\n",
    "\n",
    "# Enter your own file path here, in the path it should contain three\n",
    "# directories, model, data, word2vec\n",
    "FILE_PATH = '../files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Sports data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sports_dic = {'basketball':1, 'hockey':2, 'baseball':3, 'tennis':4, 'volleyball':5}\n",
    "sp_data = Data(sports_dic, FILE_PATH)\n",
    "sp_df = sp_data.csv_df(['text']) # load data\n",
    "rm_hashtags = ['#'+s for s in sports_dic.keys()]\n",
    "sp_data.pre_process(sp_df, rm_list=rm_hashtags) # pre-process data\n",
    "# save this to csv \n",
    "sp_df.to_csv(FILE_PATH+'data/all_sports.csv', index=False)\n",
    "sp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if you want to save the processed file to csv\n",
    "sp_df.to_csv('../files/data/all_sports_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets take a look of the \n",
    "sp_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# comment out if do not want class balance\n",
    "\n",
    "# airline_df = airline_data.balance_class(airline_df)\n",
    "# # and check again\n",
    "# airline_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train or load the model\n",
    "model = sp_data.build_wordvec(size=600, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# max_len is the max length of a sentence in our data, this decides the padding\n",
    "max_len = sp_data.max_len(sp_df)\n",
    "# convert our aline data to vector\n",
    "data = sp_data.convert2vec(sp_df, max_len, model, name='sports-600')\n",
    "#data = airline_data.standarize(data)\n",
    "sp_data.save_vec(data, name='sports-600')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can uncomment this to check if the wordvec makes sense\n",
    "# model.wv.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create data that gets fed into classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N, M, D = data.shape\n",
    "print \"N, M, D:\", N, M, D\n",
    "data = data.reshape(-1, 1, M, D).astype(theano.config.floatX) # theano needs this way\n",
    "label = sp_df['class']\n",
    "label = np.int8(label) - 1# seems like theano also needs this\n",
    "print data.shape\n",
    "print label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train our model or load model if it exists\n",
    "def train_cnn(net, X_train, y_train, model_name='nn_cnn001'):\n",
    "    model_file = FILE_PATH+'model/' + model_name\n",
    "    if os.path.isfile(model_file):\n",
    "        print (\"Loading existing model ...\")\n",
    "        net.load_params_from(model_file)\n",
    "    else:\n",
    "        # Train the network\n",
    "        net.fit(X_train, y_train)\n",
    "        net.save_params_to(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "cnn= build_cnn(M, D)\n",
    "# train\n",
    "train_cnn(cnn, data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize.plot_conv_weights(cnn.layers_['conv2d1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now transfer to svm\n",
    "# stratified cross-validation\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "n_cv = 1\n",
    "for train_index, val_index in sss.split(data, label):\n",
    "    t1 = time.time()\n",
    "    data_train, data_val = data[train_index], data[val_index]\n",
    "    label_train, label_val = label[train_index], label[val_index]\n",
    "    \n",
    "    freq_train = itemfreq(label_train)\n",
    "    print \"train freq\", freq_train[:,1]\n",
    "    freq_val = itemfreq(label_val)\n",
    "    print \"val freq\", freq_val[:,1]\n",
    "\n",
    "    # pass through cnn\n",
    "    extract_train = extract_features(cnn, data_train)\n",
    "    extract_val = extract_features(cnn, data_val)\n",
    "    clf = SVC(verbose=True, random_state=None)\n",
    "    print \"Training cv {} ...\".format(n_cv)\n",
    "    clf.fit(extract_train, label_train)\n",
    "    acc = clf.score(extract_val, label_val)\n",
    "    t2 = time.time()\n",
    "    \n",
    "    print acc\n",
    "    print \"\\n\"\n",
    "    print \"Time took: {0:.2f} min\".format((t2-t1)/60)\n",
    "    n_cv += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "joblib.dump(clf, FILE_PATH+'svm-final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
