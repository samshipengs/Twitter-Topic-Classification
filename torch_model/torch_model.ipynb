{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "/home/sam/torch/install/share/lua/5.1/cunn/init.lua:1: module 'cutorch' not found:\n\tno field package.preload['cutorch']\n\tno file '/home/sam/.luarocks/share/lua/5.1/cutorch.lua'\n\tno file '/home/sam/.luarocks/share/lua/5.1/cutorch/init.lua'\n\tno file '/home/sam/torch/install/share/lua/5.1/cutorch.lua'\n\tno file '/home/sam/torch/install/share/lua/5.1/cutorch/init.lua'\n\tno file './cutorch.lua'\n\tno file '/home/sam/torch/install/share/luajit-2.1.0-beta1/cutorch.lua'\n\tno file '/usr/local/share/lua/5.1/cutorch.lua'\n\tno file '/usr/local/share/lua/5.1/cutorch/init.lua'\n\tno file '/home/sam/torch/install/lib/cutorch.so'\n\tno file '/home/sam/.luarocks/lib/lua/5.1/cutorch.so'\n\tno file '/home/sam/torch/install/lib/lua/5.1/cutorch.so'\n\tno file './cutorch.so'\n\tno file '/usr/local/lib/lua/5.1/cutorch.so'\n\tno file '/usr/local/lib/lua/5.1/loadall.so'\nstack traceback:\n\t[C]: in function 'require'\n\t/home/sam/torch/install/share/lua/5.1/cunn/init.lua:1: in main chunk\n\t[C]: in function 'require'\n\t[string \"-- load libraries...\"]:10: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/sam/torch/install/share/lua/5.1/itorch/main.lua:210: in function </home/sam/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/home/sam/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/home/sam/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/home/sam/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/home/sam/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/sam/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00405d50",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "/home/sam/torch/install/share/lua/5.1/cunn/init.lua:1: module 'cutorch' not found:\n\tno field package.preload['cutorch']\n\tno file '/home/sam/.luarocks/share/lua/5.1/cutorch.lua'\n\tno file '/home/sam/.luarocks/share/lua/5.1/cutorch/init.lua'\n\tno file '/home/sam/torch/install/share/lua/5.1/cutorch.lua'\n\tno file '/home/sam/torch/install/share/lua/5.1/cutorch/init.lua'\n\tno file './cutorch.lua'\n\tno file '/home/sam/torch/install/share/luajit-2.1.0-beta1/cutorch.lua'\n\tno file '/usr/local/share/lua/5.1/cutorch.lua'\n\tno file '/usr/local/share/lua/5.1/cutorch/init.lua'\n\tno file '/home/sam/torch/install/lib/cutorch.so'\n\tno file '/home/sam/.luarocks/lib/lua/5.1/cutorch.so'\n\tno file '/home/sam/torch/install/lib/lua/5.1/cutorch.so'\n\tno file './cutorch.so'\n\tno file '/usr/local/lib/lua/5.1/cutorch.so'\n\tno file '/usr/local/lib/lua/5.1/loadall.so'\nstack traceback:\n\t[C]: in function 'require'\n\t/home/sam/torch/install/share/lua/5.1/cunn/init.lua:1: in main chunk\n\t[C]: in function 'require'\n\t[string \"-- load libraries...\"]:10: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/sam/torch/install/share/lua/5.1/itorch/main.lua:210: in function </home/sam/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/home/sam/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/home/sam/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/home/sam/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/home/sam/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/sam/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00405d50"
     ]
    }
   ],
   "source": [
    "-- load libraries\n",
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'nnx'\n",
    "require 'optim'\n",
    "require 'image'\n",
    "-- require 'dataset-mnist'\n",
    "require 'pl'\n",
    "require 'paths'\n",
    "require 'cunn'\n",
    "npy4th = require 'npy4th'\n",
    "------------------------------------------------------------------------------\n",
    "opt = {\n",
    "        save = 'logs',          -- file to save network after each epoch\n",
    "        batchSize = 10,         -- mini-batch size\n",
    "        learningRate = 0.05,    -- learning rate, for SGD only\n",
    "        momentum = 0,           -- momentum, for SGD only\n",
    "        max_epochs = 30,        -- Number of epochs to train the model for\n",
    "        optimization = 'SGD',   -- optimization: SGD | LBFGS\n",
    "        maxIter = 3,            -- maximum nb of iterations per batch, for LBFGS\n",
    "        coefL1 = 0,             -- L1 penalty on the weights\n",
    "        coefL2 = 0,             -- L2 penalty on the weights\n",
    "        plot = true,            -- plot while training\n",
    "}\n",
    "\n",
    "-- fix seed\n",
    "-- torch.manualSeed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function cnn()\n",
    "    -- use floats for SGD\n",
    "    torch.setdefaulttensortype('torch.FloatTensor')\n",
    "    -- define model to train\n",
    "    classes = {'1','2'}\n",
    "    -- geometry: width and height of input images\n",
    "    geometry = {17,50}\n",
    "    model = nn.Sequential()\n",
    "    -- convolutional network \n",
    "    -- stage 1 : mean suppresion -> filter bank -> squashing -> max pooling\n",
    "    -- MM constructs the Toeplitz matrix and does matrix multiplication\n",
    "    -- Now the best option is to use SpatialConvolutionMM on both CPU and GPU!\n",
    "    -- It's the fastest, it doesn't have any restrictions wrt sizes (SpatialConvolutionCUDA only supports square sizes)\n",
    "    model:add(nn.SpatialConvolutionMM(1, 32, 5, 5))\n",
    "    -- model:add(nn.SpatialConvolutionMM(1, 64, 5, 5, 1, 1, 2, 2))\n",
    "    model:add(nn.Tanh())\n",
    "    model:add(nn.SpatialMaxPooling(3, 3, 3, 3, 1, 1))\n",
    "    -- model:add(nn.SpatialMaxPooling(3, 3, 3, 3, 1, 1))\n",
    "    -- stage 2 : mean suppresion -> filter bank -> squashing -> max pooling\n",
    "    model:add(nn.SpatialConvolutionMM(32, 64, 5, 5))\n",
    "    -- model:add(nn.SpatialConvolutionMM(64, 64, 3, 3, 1, 1, 1, 1))\n",
    "    model:add(nn.Tanh())\n",
    "    -- model:add(nn.ReLU())\n",
    "    model:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
    "    -- stage 3 : standard 2-layer MLP:\n",
    "    model:add(nn.Reshape(64*3*3))\n",
    "    -- model:add(nn.Reshape(64*5*5))\n",
    "    model:add(nn.Linear(64*3*3, 200))\n",
    "    -- model:add(nn.Linear(64*5*5, 200))\n",
    "    -- model:add(nn.Dropout(0.5)) -- A\n",
    "    model:add(nn.Tanh())\n",
    "    -- model:add(nn.ReLU())\n",
    "    model:add(nn.Linear(200, #classes))\n",
    "    -- softmax layer\n",
    "    model:add(nn.LogSoftMax())\n",
    "--      model:add(nn.SoftMax())\n",
    "\n",
    "    -- use model on gpu\n",
    "    model = model:cuda()\n",
    "\n",
    "    -- retrieve parameters and gradients\n",
    "    parameters,gradParameters = model:getParameters()\n",
    "\n",
    "    -- -- loss function\n",
    "    criterion = nn.ClassNLLCriterion()\n",
    "    criterion = criterion:cuda()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create train and test dataset and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function prepare_data()\n",
    "    -- nbTrainingPatches = 60000\n",
    "    -- nbTestingPatches = 10000\n",
    "    nbTrainingPatches = 2000\n",
    "    nbTestingPatches = 1000\n",
    "\n",
    "    -- loading index\n",
    "    bag_n = torch.randperm(nbTrainingPatches)[{ {1,1800} }]:long()\n",
    "    -- create training set and normalize\n",
    "    trainData = mnist.loadTrainSet(nbTrainingPatches, bag_n, geometry)\n",
    "    trainData:normalizeGlobal(mean, std)\n",
    "    -- create test set and normalize\n",
    "    testData = mnist.loadTestSet(nbTestingPatches, _, geometry)\n",
    "    testData:normalizeGlobal(mean, std)\n",
    "\n",
    "--     -- take a quick look of the data\n",
    "--     itorch.image(trainData.data[100]) -- display the 100-th image in train\n",
    "--     print(classes[trainData.labels[100]]-1)\n",
    "--     itorch.image(testData.data[100]) -- display the 100-th image in test\n",
    "--     print(classes[testData.labels[100]]-1)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data to use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function convert_gpu()\n",
    "    trainData.data = trainData.data:cuda()\n",
    "    trainData.labels = trainData.labels:cuda()\n",
    "\n",
    "    testData.data = testData.data:cuda()\n",
    "    testData.labels = testData.labels:cuda()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- print(trainData)\n",
    "-- print(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function conf_log(n)\n",
    "    -- this matrix records the current confusion across classes\n",
    "    confusion = optim.ConfusionMatrix(classes)\n",
    "    -- log results to files\n",
    "    name_acc = 'accuracy' .. tostring(n) .. '.log'\n",
    "    name_err = 'err' .. tostring(n) .. '.log'\n",
    "    accLogger = optim.Logger(paths.concat(opt.save, name_acc))\n",
    "    errLogger = optim.Logger(paths.concat(opt.save, name_err))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- training function\n",
    "function train(dataset)\n",
    "    -- epoch tracker\n",
    "    epoch = epoch or 1\n",
    "\n",
    "    -- local vars\n",
    "    local time = sys.clock()\n",
    "    local trainError = 0\n",
    "    \n",
    "    -- do one epoch\n",
    "--     print('<trainer> on training set:')\n",
    "--     print('<trainer> online epoch # ' .. epoch .. ' [batchSize = ' .. opt.batchSize .. ']')\n",
    "    for t = 1,dataset:size(),opt.batchSize do\n",
    "        -- create mini batch\n",
    "        local inputs = torch.Tensor(opt.batchSize,1,geometry[1],geometry[2])\n",
    "        local targets = torch.Tensor(opt.batchSize)\n",
    "        -- convert to cuda tensor\n",
    "        inputs = inputs:cuda()\n",
    "        targets = targets:cuda()\n",
    "        local k = 1\n",
    "        for i = t,math.min(t+opt.batchSize-1,dataset:size()) do\n",
    "            -- load new sample\n",
    "            local sample = dataset[i]\n",
    "            local input = sample[1]:clone()\n",
    "            local _,target = sample[2]:clone():max(1)\n",
    "            target = target:squeeze()\n",
    "            inputs[k] = input\n",
    "            targets[k] = target\n",
    "            k = k + 1\n",
    "        end\n",
    "        -- create closure to evaluate f(X) and df/dX\n",
    "        local feval = function(x)\n",
    "            -- just in case:\n",
    "            collectgarbage()\n",
    "\n",
    "            -- get new parameters\n",
    "            if x ~= parameters then\n",
    "                parameters:copy(x)\n",
    "            end\n",
    "\n",
    "            -- reset gradients\n",
    "            gradParameters:zero()\n",
    "\n",
    "            -- evaluate function for complete mini batch\n",
    "            local outputs = model:forward(inputs)\n",
    "            local f = criterion:forward(outputs, targets)\n",
    "\n",
    "            -- train error\n",
    "            trainError = trainError + f\n",
    "            \n",
    "            -- estimate df/dW\n",
    "            local df_do = criterion:backward(outputs, targets)\n",
    "            model:backward(inputs, df_do)\n",
    "\n",
    "            -- penalties (L1 and L2):\n",
    "            if opt.coefL1 ~= 0 or opt.coefL2 ~= 0 then\n",
    "                -- locals:\n",
    "                local norm,sign= torch.norm,torch.sign\n",
    "\n",
    "                -- Loss:\n",
    "                f = f + opt.coefL1 * norm(parameters,1)\n",
    "                f = f + opt.coefL2 * norm(parameters,2)^2/2\n",
    "\n",
    "                -- Gradients:\n",
    "                gradParameters:add( sign(parameters):mul(opt.coefL1) + parameters:clone():mul(opt.coefL2) )\n",
    "            end\n",
    "\n",
    "            -- update confusion\n",
    "            for i = 1,opt.batchSize do\n",
    "                confusion:add(outputs[i], targets[i])\n",
    "            end\n",
    "\n",
    "            -- return f and df/dX\n",
    "            return f,gradParameters\n",
    "        end\n",
    "\n",
    "        -- optimize on current mini-batch\n",
    "        if opt.optimization == 'LBFGS' then\n",
    "\n",
    "            -- Perform LBFGS step:\n",
    "            lbfgsState = lbfgsState or {\n",
    "                maxIter = opt.maxIter,\n",
    "                lineSearch = optim.lswolfe\n",
    "            }\n",
    "            optim.lbfgs(feval, parameters, lbfgsState)\n",
    "\n",
    "            -- disp report:\n",
    "            print('LBFGS step')\n",
    "            print(' - progress in batch: ' .. t .. '/' .. dataset:size())\n",
    "            print(' - nb of iterations: ' .. lbfgsState.nIter)\n",
    "            print(' - nb of function evalutions: ' .. lbfgsState.funcEval)\n",
    "\n",
    "        elseif opt.optimization == 'SGD' then\n",
    "\n",
    "        -- Perform SGD step:\n",
    "        sgdState = sgdState or {\n",
    "            learningRate = opt.learningRate,\n",
    "            momentum = opt.momentum,\n",
    "            learningRateDecay = 5e-7\n",
    "        }\n",
    "        optim.sgd(feval, parameters, sgdState)\n",
    "\n",
    "        -- disp progress\n",
    "        xlua.progress(t, dataset:size())\n",
    "\n",
    "        else\n",
    "            error('unknown optimization method')\n",
    "        end\n",
    "    end\n",
    "   \n",
    "    -- time taken\n",
    "    time = sys.clock() - time\n",
    "    time = time / dataset:size()\n",
    "--     print(\"<trainer> time to learn 1 sample = \" .. (time*1000) .. 'ms')\n",
    "\n",
    "    -- print confusion matrix\n",
    "--     print(confusion)\n",
    "    \n",
    "    -- train error\n",
    "    trainError = trainError / math.floor(dataset:size()/opt.batchSize)\n",
    "    -- train accuracy\n",
    "    local trainAccuracy = confusion.totalValid * 100\n",
    "    confusion:zero()\n",
    "\n",
    "    -- next epoch\n",
    "    epoch = epoch + 1\n",
    "    return trainAccuracy, trainError\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- test function\n",
    "function test(dataset)\n",
    "    -- local vars\n",
    "    local time = sys.clock()\n",
    "    local testError = 0\n",
    "    -- define pred for all test data\n",
    "    local pred_total = torch.zeros(opt.batchSize):long()\n",
    "    \n",
    "    -- test over given dataset\n",
    "--     print('<trainer> on testing Set:')\n",
    "    for t = 1,dataset:size(),opt.batchSize do\n",
    "        -- disp progress\n",
    "        xlua.progress(t, dataset:size())\n",
    "\n",
    "        -- create mini batch\n",
    "        local inputs = torch.Tensor(opt.batchSize,1,geometry[1],geometry[2])\n",
    "        local targets = torch.Tensor(opt.batchSize)\n",
    "\n",
    "        -- convert to cuda tensor\n",
    "        inputs = inputs:cuda()\n",
    "        targets = targets:cuda()\n",
    "        \n",
    "        local k = 1\n",
    "        for i = t,math.min(t+opt.batchSize-1,dataset:size()) do\n",
    "            -- load new sample\n",
    "            local sample = dataset[i]\n",
    "            local input = sample[1]:clone()\n",
    "            local _,target = sample[2]:clone():max(1)\n",
    "            target = target:squeeze()\n",
    "            inputs[k] = input\n",
    "            targets[k] = target\n",
    "            k = k + 1\n",
    "        end\n",
    "\n",
    "        -- test samples\n",
    "        local preds = model:forward(inputs)\n",
    "        local maxs, indices = torch.max(preds, 2)\n",
    "        indices = indices:long()\n",
    "        pred_total = torch.cat(pred_total, indices[{{}, 1}])\n",
    "        \n",
    "        -- compute error\n",
    "        err = criterion:forward(preds, targets)\n",
    "        testError = testError + err   \n",
    "\n",
    "        -- confusion:\n",
    "        for i = 1,opt.batchSize do\n",
    "            confusion:add(preds[i], targets[i])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    -- timing\n",
    "    time = sys.clock() - time\n",
    "    time = time / dataset:size()\n",
    "--     print(\"<trainer> time to test 1 sample = \" .. (time*1000) .. 'ms')\n",
    "\n",
    "    -- print confusion matrix\n",
    "--     print(confusion)\n",
    "    -- test error\n",
    "    testError = testError / math.floor(dataset:size()/opt.batchSize)\n",
    "    -- test accuracy\n",
    "    local testAccuracy = confusion.totalValid * 100\n",
    "    confusion:zero()\n",
    "\n",
    "    return testAccuracy, testError, pred_total[{{opt.batchSize+1, pred_total:size()[1]}}]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train out model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- -- bagging\n",
    "-- n_seed = 42\n",
    "-- N_bags = 20\n",
    "-- pred_bag = torch.zeros(1, 1000):long() -- initialize pred\n",
    "-- for i = 1, N_bags do\n",
    "--     torch.manualSeed(n_seed)\n",
    "--     print('Ensembling >>>>>>>>' .. i)\n",
    "--     -- init \n",
    "--     cnn()\n",
    "--     prepare_data()\n",
    "--     convert_gpu()\n",
    "--     conf_log(n_seed)\n",
    "    \n",
    "--     -- train\n",
    "--     n = 0\n",
    "--     while n < opt.max_epochs do\n",
    "--         n = n + 1\n",
    "--         trainAcc, trainErr = train(trainData)\n",
    "--         testAcc, testErr, pred_n = test(testData)\n",
    "        \n",
    "--         if opt.plot then\n",
    "--             -- update logger\n",
    "--             accLogger:add{['% (mean)train accuracy'] = trainAcc, ['% (mean)test accuracy'] = testAcc}\n",
    "--             errLogger:add{['% (mean)train error'] = trainErr, ['% (mean)test error'] = testErr}\n",
    "--             -- plot logger\n",
    "-- --             accLogger:style{['% (mean)train accuracy'] = '+-', ['% (mean)test accuracy'] = '+-'}\n",
    "-- --             errLogger:style{['% (mean)train error']    = '+-', ['% (mean)test error']    = '+-'}\n",
    "-- --             accLogger:plot()\n",
    "-- --             errLogger:plot()\n",
    "--         end\n",
    "--     end \n",
    "--     pred_n = pred_n:resize(1, pred_n:size()[1])\n",
    "--     pred_bag = torch.cat(pred_bag, pred_n, 1)\n",
    "--     n_seed = n_seed + i\n",
    "--     print(\"Done \" .. i)\n",
    "-- end\n",
    "\n",
    "-- pred_bag = pred_bag[{ {2,N_bags}, {} }]\n",
    "-- -- use majority vote\n",
    "-- ensembled_pred, _ =  torch.mode(pred_bag, 1)\n",
    "\n",
    "-- -- apply confusion matrix\n",
    "-- confusion_f = optim.ConfusionMatrix(classes)\n",
    "-- for i = 1, 1000 do\n",
    "--     forward_pred = -1*torch.ones(10)\n",
    "--     ind = ensembled_pred[{1, {i}}][1]\n",
    "--     forward_pred[{{ind}}] = -0.5\n",
    "--     confusion_f:add(forward_pred, testData.labels[{i}])\n",
    "-- end\n",
    "\n",
    "-- print(confusion_f)\n",
    "-- -- local final_accuracy = confusion_f.totalValid * 100\n",
    "-- final_accuracy = confusion_f.totalValid * 100\n",
    "-- print('The final ensembled (mean) accuracy is: ' .. final_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
